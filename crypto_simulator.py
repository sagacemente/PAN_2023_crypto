# -*- coding: utf-8 -*-
"""Crypto_Simulator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BjanL2mGivunzBIC5iuGhum9SDG3Z7Nf
"""

!pip install simpletransformers
!pip install tensorflow-addons

import numpy as np
import torch
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import losses
import tensorflow_addons as tfa
import os
import pandas as pd
import json
import sklearn
from sklearn.preprocessing import OneHotEncoder
from urllib import request
from simpletransformers.classification import ClassificationModel, ClassificationArgs

# Import class Vectorizer
module_url = f"https://raw.githubusercontent.com/marco-siino/DA-BT/main/code/vectorizer.py"
module_name = module_url.split('/')[-1]
print(f'Fetching {module_url}')
with request.urlopen(module_url) as f, open(module_name,'w') as outf:
  a = f.read()
  outf.write(a.decode('utf-8'))
from vectorizer import Vectorizer

class Simulator:

  def __init__(self, model, nr_runs, nr_epochs, ds, vectorize_layer, num_labels=5):
    self.num_labels = num_labels
    self.model = model
    self.nr_runs = nr_runs
    self.nr_epochs = nr_epochs
    self.ds = ds  ## take only the ds
    self.vectorize_layer = vectorize_layer
    self.setup()    

  # Prior data and model setups before running.
  def setup(self):    
    # To store maximum accuracy for each run.
    self.runs_accuracy = []    
    # Dictionary size.
    self.max_features=len(self.vectorize_layer.get_vocabulary()) + 1
    # Now specific setup parameters setup for each model
    if self.model=="cnn":
      self.setup_shallow()
      print("\nSetup for shallow model completed.")
    
    if self.model == "roberta":
      self.setup_transformer()
      print("\nSetup for Roberta completed.")

  def setup_shallow(self):
    # Word embedding dimensions.
    self.embedding_dim = 100
    #For reproducibility.
    tf.random.set_seed(1)   

  def setup_transformer(self):
    # Convert train and test keras DS into DFs.
    self.train_df, self.test_df = self.ds.get_train_test_df()

  def run(self):
    if self.model == "cnn":
      self.run_cnn()
    elif self.model == "roberta":
      self.run_roberta()

  def run_cnn(self): 
    METRICS = [
      #tf.keras.metrics.CategoricalAccuracy(name='acc'),
      tfa.metrics.F1Score(num_classes=self.num_labels,
                          average='macro', 
                          name='f1')
               ]    
    for run in range(1,(self.nr_runs+1)):
      epochs_accuracy = []
      model = tf.keras.Sequential([
                                      tf.keras.Input(shape=(1,), dtype=tf.string),
                                      self.vectorize_layer,
                                      layers.Embedding(self.max_features + 1, self.embedding_dim),                     
                                      layers.Dropout(0.8),

                                      layers.Conv1D(256,16,activation='relu'),
                                      layers.MaxPooling1D(),
                                      layers.Dropout(0.6),

                                      layers.Dense(512,activation='relu'),
                            
                                      layers.GlobalAveragePooling1D(),
                                      layers.Dropout(0.2),
                                      layers.Dense(self.num_labels, activation='softmax')
                                      ])
      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=METRICS)                                                                                                                    

      for epoch in range (0,self.nr_epochs):
          history = model.fit(
            self.ds.train_set,
            validation_data = self.ds.test_set,
            epochs=1,
            shuffle=False,)
          accuracy = history.history['f1']
          print("Run: ",run,"/ Accuracy on test set at epoch ",epoch," is: ", accuracy[0],"\n")
          epochs_accuracy.append(accuracy[0])
      print("Accuracies over epochs:",epochs_accuracy,"\n")
      self.runs_accuracy.append(max(epochs_accuracy))

    self.runs_accuracy.sort()
    print("\n\n Over all runs maximum accuracies on test set are:", self.runs_accuracy)
    print("The median is:", self.runs_accuracy[2],"\n\n\n")
    # Final Result on test set
    if (self.runs_accuracy[2]-self.runs_accuracy[0])>(self.runs_accuracy[4]-self.runs_accuracy[2]):
      max_range_from_median = self.runs_accuracy[2]-self.runs_accuracy[0]
    else:
      max_range_from_median = self.runs_accuracy[4]-self.runs_accuracy[2]
    final_result = str(self.runs_accuracy[2])+" +/- "+ str(max_range_from_median)
    print("CNN Accuracy Score on test set -> ",final_result)

  def run_roberta(self):
    #functions defined inside one function
    def f1(y_true, y_pred):
      TP = np.sum(np.multiply([i==True for i in y_pred], y_true))
      TN = np.sum(np.multiply([i==False for i in y_pred], [not(j) for j in y_true]))
      FP = np.sum(np.multiply([i==True for i in y_pred], [not(j) for j in y_true]))
      FN = np.sum(np.multiply([i==False for i in y_pred], y_true))
      precision = TP/(TP+FP)
      recall = TP/(TP+FN)
      if precision != 0 and recall != 0:
        f1 = (2 * precision * recall) / (precision + recall)
      else:
        f1 = 0
      return f1
    def f1_macro(y_true, y_pred):
      macro = []
      for i in np.unique(y_true):
        modified_true = [i==j for j in y_true]
        modified_pred = [i==j for j in y_pred]
        score = f1(modified_true, modified_pred)
        macro.append(score)
      return np.mean(macro)
    
    self.metric = f1_macro
    cuda_available = torch.cuda.is_available()

    model_args = ClassificationArgs(num_train_epochs=2, 
                                    overwrite_output_dir=True,
                                    manual_seed = 4,
                                    use_multiprocessing = True,
                                    train_batch_size = 16,
                                    eval_batch_size = 1,
                                    no_save=True, 
                                    no_cache=True)

    runs_accuracy = []
    for run in range(1,(self.nr_runs+1)):
      epochs_accuracy=[]
      model = ClassificationModel("roberta", 
                                      'roberta-base', 
                                      args = model_args, 
                                      num_labels=self.num_labels, 
                                      use_cuda=cuda_available)
      for epoch in range (0,self.nr_epochs):
        print("\nEPOCH NUMBER: ", epoch)
        # train model
        print("\nNOW TRAIN THE MODEL.")
        model.train_model(self.train_df,
                          show_running_loss=True,
                          acc=self.metric)
        print("\nNOW EVALUATE THE TEST DF.")
        # Evaluate the model
        result, model_outputs, wrong_predictions = model.eval_model(self.test_df,
                                                                    acc=self.metric)
        # Results on test set.
        print(result)
        macrof1 = result['acc']
        print("Macro F1 on test set is:",macrof1,"\n\n")
        epochs_accuracy.append(macrof1)

      print(epochs_accuracy)
      runs_accuracy.append(max(epochs_accuracy))

    runs_accuracy.sort()
    print("\n\n Over all runs maximum accuracies are:", runs_accuracy)
    print("The median is:",runs_accuracy[2])
    if (runs_accuracy[2]-runs_accuracy[0])>(runs_accuracy[4]-runs_accuracy[2]):
      max_range_from_median = runs_accuracy[2]-runs_accuracy[0]
    else:
      max_range_from_median = runs_accuracy[4]-runs_accuracy[2]
    final_result = str(runs_accuracy[2])+" +/- "+ str(max_range_from_median)
    print("RoBERTa Accuracy Score on Test set -> ",final_result)